# https://colab.research.google.com/github/dianna-ai/dianna/blob/main/tutorials/rise_imagenet.ipynb#scrollTo=ab3bd199

# libraries ----
import warnings
warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf
import numpy as np
from pathlib import Path

# keras model and preprocessing tools
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.models import load_model # added to load resnet Raphael model
from keras import backend as K
from keras import utils

# dianna library for explanation
import dianna
from dianna import visualization

# for plotting
%matplotlib inline
from matplotlib import pyplot as plt

# 1 - Loading the pretrained Raphael model

# loading the resnet model used in the Raphael paper ( see here to get it):
# https://www.dropbox.com/scl/fo/0e927qf6sjldoiaiatjey/h?rlkey=ohj36i4bnf7nou2zyfua6pim8&dl=0

ResNet_Path = "../models/resnet50_model.h5"

class Model():
     def __init__(self):
         K.set_learning_phase(0)
         #self.model = ResNet50()
         self.model = load_model(ResNet_Path)
         self.input_size = (224, 224)
         # put all other information needed to run the model here, see script from Raphael article

     def run_on_batch(self, x):
         return self.model.predict(x)

model = Model()

# Load and preprocess image to be explained
def load_img(path):
    img = utils.load_img(path)
    x = utils.img_to_array(img)
    x = preprocess_input(x)
    return img, x

# Call the function to load an image of a single instance in the test data from the `img` folder.
img, x = load_img(Path('img', '0_Edinburgh_Nat_Gallery.jpg'))
plt.imshow(img)

# 2 - Compute and visualize the relevance scores
# Compute the pixel relevance scores using RISE and visualize them on the input image.

#RISE masks random portions of the input image and passes the masked image through
# the model — the masked portion that decreases accuracy the most is the most 
# “important” portion.#To call the explainer and generate relevance scores map, 
# the user need to specifiy the number of masks being randomly generated
# (`n_masks`), the resolution of features in masks (`feature_res`) 
# and for each mask and each feature in the image, the probability of being kept 
# unmasked (`p_keep`).

# takes about 35-40 minutes to run
relevances = dianna.explain_image(model.run_on_batch, x, method="RISE",
                                labels=[i for i in range(1000)],
                                n_masks=1000, feature_res=6, p_keep=.1,
                                axis_labels={2: 'channels'})

# Make predictions and select the top prediction.
def class_name(idx):
    return decode_predictions(np.eye(1, 1000, idx))[0][0][1]

# print the name of predicted class, taking care of adding a batch axis to the model input
class_name(np.argmax(model.predict(x[None, ...])))

# Visualize the relevance scores for the predicted class on top of the input image.
predictions = model.model.predict(x[None, ...])
prediction_ids = np.argsort(predictions)[0][-1:-6:-1]
prediction_ids

for class_idx in prediction_ids:
    print(f'Explanation for `{class_name(class_idx)}` ({predictions[0][class_idx]})')
    visualization.plot_image(relevances[class_idx], utils.img_to_array(img)/255., heatmap_cmap='jet')

# Conclusions ----
# The relevance scores are generated by passing multiple randomly masked inputs to the black-box model 
# and averaging their scores. The idea behind this is that whenever a mask preserves important parts 
# of the image it gets higher score. 

# The example here shows that the RISE method evaluates the relevance of each pixel/super pixel to 
# the classification. Pixels characterizing the bee are highlighted by the XAI approach, which gives 
# an intuition on how the model classifies the image. The results are reasonable, based on the human 
# visual preception of the image.
